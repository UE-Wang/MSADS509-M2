{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "610a8639",
   "metadata": {},
   "source": [
    "# USADS509 M2 UE Wang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f79baf9",
   "metadata": {},
   "source": [
    "# ADS 509 Assignment 2.1: Tokenization, Normalization, Descriptive Statistics \n",
    "\n",
    "This notebook holds Assignment 2.1 for Module 2 in ADS 509, Applied Text Mining. Work through this notebook, writing code and answering questions where required. \n",
    "\n",
    "In the previous assignment you put together Twitter data and lyrics data on two artists. In this assignment we explore some of the textual features of those data sets. If, for some reason, you did not complete that previous assignment, data to use for this assignment can be found in the assignment materials section of Blackboard. \n",
    "\n",
    "This assignment asks you to write a short function to calculate some descriptive statistics on a piece of text. Then you are asked to find some interesting and unique statistics on your corpora. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae8e2e1",
   "metadata": {},
   "source": [
    "## General Assignment Instructions\n",
    "\n",
    "These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it. \n",
    "\n",
    "One sign of mature code is conforming to a style guide. We recommend the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html). If you use a different style guide, please include a cell with a link. \n",
    "\n",
    "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential `import` statements and make sure that all such statements are moved into the designated cell. \n",
    "\n",
    "Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions to answer. The questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you. *Make sure to answer every question marked with a `Q:` for full credit.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d096b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "sw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b555ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional import statements you need here\n",
    "\n",
    "import glob\n",
    "import regex as re\n",
    "#import fasttext\n",
    "import sqlite3\n",
    "import html\n",
    "import textacy\n",
    "import textacy.preprocessing as tprep\n",
    "import nltk\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.util import compile_prefix_regex, \\\n",
    "                       compile_infix_regex, compile_suffix_regex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "923b5a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change `data_location` to the location of the folder on your machine.\n",
    "\n",
    "data_location = \"/Users/UE/Desktop/M1 Results\"\n",
    "# These subfolders should still work if you correctly stored the \n",
    "# data from the Module 1 assignment\n",
    "twitter_folder = \"twitter/\"\n",
    "lyrics_folder = \"lyrics/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06522af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_stats(tokens, num_tokens = 5, verbose=True) :\n",
    "    \"\"\"\n",
    "        Given a list of tokens, print number of tokens, number of unique tokens, \n",
    "        number of characters, lexical diversity (https://en.wikipedia.org/wiki/Lexical_diversity), \n",
    "        and num_tokens most common tokens. Return a list with the number of tokens, number\n",
    "        of unique tokens, lexical diversity, and number of characters. \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Fill in the correct values here. \n",
    "    \n",
    "    num_tokens = len(tokens)\n",
    "    num_unique_tokens = len(set(tokens))  \n",
    "    lexical_diversity = num_unique_tokens / num_tokens\n",
    "    num_characters = sum(len(s) for s in tokens)\n",
    "    \n",
    "    if verbose :        \n",
    "        print(f\"There are {num_tokens} tokens in the data.\")\n",
    "        print(f\"There are {num_unique_tokens} unique tokens in the data.\")\n",
    "        print(f\"There are {num_characters} characters in the data.\")\n",
    "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")        \n",
    "        print (f\"The five most common words are:\")\n",
    "        print(Counter(tokens).most_common(5))\n",
    "        \n",
    "    return([num_tokens, num_unique_tokens,\n",
    "            lexical_diversity,\n",
    "            num_characters])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59dcf058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13 tokens in the data.\n",
      "There are 9 unique tokens in the data.\n",
      "There are 55 characters in the data.\n",
      "The lexical diversity is 0.692 in the data.\n",
      "The five most common words are:\n",
      "[('text', 3), ('here', 2), ('example', 2), ('is', 1), ('some', 1)]\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"here is some example text with other example text here in this text\"\"\".split()\n",
    "assert(descriptive_stats(text, verbose=True)[0] == 13)\n",
    "assert(descriptive_stats(text, verbose=False)[1] == 9)\n",
    "assert(abs(descriptive_stats(text, verbose=False)[2] - 0.69) < 0.02)\n",
    "assert(descriptive_stats(text, verbose=False)[3] == 55)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e7e1a2",
   "metadata": {},
   "source": [
    "Q: Why is it beneficial to use assertion statements in your code? \n",
    "\n",
    "A: <!-- Your answer here --> \n",
    "\n",
    "Using assertion statements can help ensure that the code is running as expected. They allow users to spot issues before actually running the dataset, acting as a form of pre-execution checks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3bf93e",
   "metadata": {},
   "source": [
    "## Data Input\n",
    "\n",
    "Now read in each of the corpora. For the lyrics data, it may be convenient to store the entire contents of the file to make it easier to inspect the titles individually, as you'll do in the last part of the assignment. In the solution, I stored the lyrics data in a dictionary with two dimensions of keys: artist and song. The value was the file contents. A data frame would work equally well. \n",
    "\n",
    "For the Twitter data, we only need the description field for this assignment. Feel free all the descriptions read it into a data structure. In the solution, I stored the descriptions as a dictionary of lists, with the key being the artist. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ae6c341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample for robynkonichiwa: ['\"Include Me Out\"\\n\\n\\n\\nIt is really very simple\\nJust a single pulse, repeated at a regular interval\\n\\nMmm, hmm\\nDon\\'t include me out, no\\nDon\\'t include me out\\n\\nOne time for the records and the hits\\nTwo for your money-maker, shake, boom\\nThree times for the lucky and the dead\\n\\nOne time for the sorry and safe\\nTwo for the beggar and his company\\nThree times for the sinner and the saint\\n\\nYeah, bow down all you wicked and the vain\\nBow to the miracle, the em, na, na\\nThree times and the devil will be gone\\n\\nOne time for the fire, bring it on\\nTwo for the boogie, gotta bang the beat\\nThree times for the ladies, show me some love\\n\\nTalking \\'bout everyone, every day, all day\\n\\nAnd if your world should fall apart\\nThere\\'s plenty room inside my heart\\nJust don\\'t include me out\\nDon\\'t include me out\\n\\nAnd if your world should fall apart\\nI still got room inside my heart\\nJust don\\'t include me out\\nDon\\'t include me out, d-d-don\\'t include me out\\n\\nAll hail to the mamas who hold it down\\nHail to the pillar of the family\\nThis one\\'s for the granny, take a bow\\n\\nOne time for the crazy and the bent\\nCome on, all you trannies click your heels for me\\nAll praise the fugeses and the gems\\n\\nTalking \\'bout everyone, every day, all day, oh yeah\\n\\nAnd if your world should fall apart\\nThere\\'s plenty room inside my heart\\nJust don\\'t include me out\\nJust don\\'t include me out\\n\\nAnd if your world should fall apart\\nI still got room inside my heart\\nJust don\\'t include me out\\nDon\\'t include me out, d-d-don\\'t include me out\\n\\nCan I get a beat, beat for all of my watchamacallits\\nDoing whatever and with whoever they like?\\nCan I get a beat, beat for all of my watchamacallits\\nDoing whatever and with whoever they like?\\n\\nCan I get a bam, bam for all of my watchamacallits\\nDoing whatever and with whoever they like?\\nCan I get a bam, bam for all of my watchamacallits\\nDoing whatever and with whoever they like?\\n\\nI\\'m talking about everyone, every day, all day, hey\\n\\nAnd if your world should fall apart\\nThere\\'s plenty room inside my heart\\nJust don\\'t include me out\\nDon\\'t include me out\\n\\nAnd if your world should fall apart\\nI still got room inside my heart\\nJust don\\'t include me out\\nDon\\'t include me out\\n\\nAnd if your world should fall apart\\nThere\\'s plenty room inside my heart\\nJust don\\'t include me out, hey, hey\\n\\nAnd if your world should fall apart\\nI still got room inside my heart, yeah\\nJust don\\'t include me out, hey\\n']\n",
      "--------------------------------------------\n",
      "Sample for cher: ['\"Come And Stay With Me\"\\n\\n\\n\\nI\\'ll send away all my false pride\\nAnd I\\'ll forsake all of my life\\nYes I\\'ll be as true as true can be\\nIf you\\'ll come and stay with me\\n\\nAll lovers of the past, I\\'ll leave behind\\nThey\\'ll never be another on my mind\\nI\\'ll do all I can so you\\'ll feel free\\nIf you\\'ll come and stay with me\\n\\nThe promise I made most faithfully\\nI\\'ll keep still if you decide to leave\\nI\\'ll try and see that you have all you need\\nIf you\\'ll come and stay with me\\n\\nYes I\\'ll be as true as true can be\\nIf you\\'ll come and stay with me\\n\\nLive a life no others have ever known\\nBut I know you think that I\\'m hardly grown\\nOh thank God at last and finally\\nI can see you\\'re gonna stay with me\\nI can see you\\'re gonna stay with me\\n']\n"
     ]
    }
   ],
   "source": [
    "# Read in the lyrics data\n",
    "\n",
    "lyrics_data = {}\n",
    "\n",
    "lyrics_path = os.path.join(data_location, lyrics_folder)\n",
    "\n",
    "for artist_folder in os.listdir(lyrics_path):\n",
    "    artist_folder_path = os.path.join(lyrics_path, artist_folder)\n",
    "\n",
    "    if os.path.isdir(artist_folder_path):\n",
    "        # Use glob to find all text files in the artist folder\n",
    "        file_paths = glob.glob(os.path.join(artist_folder_path, '*.txt'))\n",
    "\n",
    "        # Read the contents of each text file and store in artist_lyrics\n",
    "        artist_lyrics = [open(file_path, 'r').read() for file_path in file_paths]\n",
    "\n",
    "        lyrics_data[artist_folder] = artist_lyrics\n",
    "        \n",
    "print(\"Sample for robynkonichiwa:\", lyrics_data['robyn'][:1])\n",
    "print(\"--------------------------------------------\")\n",
    "print(\"Sample for cher:\", lyrics_data['cher'][:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30b18bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample for robynkonichiwa: ['\"I love chill\" â€¢Facebook / Instagram / SoundCloud: AngelxoArtsâ€¢ https://t.co/447okKLKzAâ€¦', \"books, movies, music, nature & TV shows. OG Sweetee since '12 thanks to YouTube recommending 'This Feeling' on my homepage â™¥ï¸\", '(Am)auteur en herbe ğŸŒ± - juriste en paille ğŸ¤¡ - Ami des fleurs ğŸŒ¸ğŸŒˆ (sans la main verte) - music & books - #morecomingsoon... (si on en voit le bout)', 'This Twitter profile is full of sarcasm and rants with the occasional moan, dont like me dont follow me! KLF Stan Account Aspiring Youth Council rep', 'Flora Youssef - Blogger & Founder Posting review articles about the latest music ğŸµ https://t.co/dx4hoIom7T https://t.co/KsplT6mZzs']\n",
      "-------------------------------------------\n",
      "Sample for cher: ['ğ™¿ğš›ğš˜ğšğš ğšœğšğš™ğš™ğš˜ğš›ğšğšğš› ğš˜ğš ğš–ğšğšœğšœğš¢ ğš‹ğšğš—ğšœ & ğš•ğšğšğšğš’ğš—ğšğšœ', '163ãï¼æ„›ã‹ã£ã·ğŸ’œ26æ­³ğŸ’ å·¥ã€‡å¥½ããªå¥³ã®å­ğŸ’“ ãƒ•ã‚©ãƒ­ãƒ¼ã—ã¦ãã‚ŒãŸã‚‰DMã—ã¾ã™ğŸ§¡', 'csu', 'Writer @Washinformer @SpelmanCollege alumna #DCnative Award-winning journalist & PR pro @IABC Fellow & Past Chair IG: bcscomm Email: wibsiler@gmail.com', 'Iâ€™m unemployed and live with my parents. MOOPS!']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "twitter_files = os.path.join(data_location, twitter_folder)\n",
    "desc_files = [f for f in os.listdir(twitter_files) if \"followers_data\" in f]\n",
    "\n",
    "twitter_data = {}\n",
    "\n",
    "for f in desc_files:\n",
    "    artist = f.split(\"_\")[0]\n",
    "    \n",
    "    if artist == 'robynkonichiwa' or artist == 'cher':\n",
    "        if artist not in twitter_data:\n",
    "            twitter_data[artist] = []  # Initialize the list for the artist if it doesn't exist\n",
    "        \n",
    "        with open(os.path.join(data_location, twitter_folder, f), 'r', encoding='utf8') as infile:\n",
    "            next(infile)\n",
    "            for idx, line in enumerate(infile.readlines()):\n",
    "                line = line.strip().split(\"\\t\") \n",
    "                if len(line) == 7:  \n",
    "                    twitter_data[artist].append(line[6])\n",
    "                    \n",
    "print(\"Sample for robynkonichiwa:\", twitter_data['robynkonichiwa'][:5])\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Sample for cher:\", twitter_data['cher'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f3b12",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Now clean and tokenize your data. Remove punctuation chacters (available in the `punctuation` object in the `string` library), split on whitespace, fold to lowercase, and remove stopwords. Store your cleaned data, which must be accessible as an interable for `descriptive_stats`, in new objects or in new columns in your data frame. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71c73d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(punctuation) # speeds up comparison\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3ecd2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your clean twitter data here\n",
    "clean_twitter = {}\n",
    "\n",
    "for artist_name, twitter_descriptions in twitter_data.items():\n",
    "    clean_twitter_descriptions = []\n",
    "\n",
    "    for twitter_description in twitter_descriptions:\n",
    "        # Remove punctuation\n",
    "        twitter_description = ''.join([ch for ch in twitter_description if ch not in punctuation])\n",
    "\n",
    "        # Split on whitespace and fold to lowercase\n",
    "        tokens_twitter = twitter_description.lower().split()\n",
    "\n",
    "        # Remove stopwords\n",
    "        tokens_twitter = [token for token in tokens_twitter if token not in sw]\n",
    "\n",
    "        clean_twitter_descriptions.append(tokens_twitter)\n",
    "\n",
    "    clean_twitter[artist_name] = clean_twitter_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "276c308c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robyn tweet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"I love chill\" â€¢Facebook / Instagram / SoundCl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>books, movies, music, nature &amp; TV shows. OG Sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Am)auteur en herbe ğŸŒ± - juriste en paille ğŸ¤¡ - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This Twitter profile is full of sarcasm and ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flora Youssef - Blogger &amp; Founder Posting revi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0  \"I love chill\" â€¢Facebook / Instagram / SoundCl...\n",
       "1  books, movies, music, nature & TV shows. OG Sw...\n",
       "2  (Am)auteur en herbe ğŸŒ± - juriste en paille ğŸ¤¡ - ...\n",
       "3  This Twitter profile is full of sarcasm and ra...\n",
       "4  Flora Youssef - Blogger & Founder Posting revi..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cher tweet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ğ™¿ğš›ğš˜ğšğš ğšœğšğš™ğš™ğš˜ğš›ğšğšğš› ğš˜ğš ğš–ğšğšœğšœğš¢ ğš‹ğšğš—ğšœ &amp; ğš•ğšğšğšğš’ğš—ğšğšœ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>163ãï¼æ„›ã‹ã£ã·ğŸ’œ26æ­³ğŸ’ å·¥ã€‡å¥½ããªå¥³ã®å­ğŸ’“ ãƒ•ã‚©ãƒ­ãƒ¼ã—ã¦ãã‚ŒãŸã‚‰DMã—ã¾ã™ğŸ§¡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>csu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Writer @Washinformer @SpelmanCollege alumna #D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iâ€™m unemployed and live with my parents. MOOPS!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0           ğ™¿ğš›ğš˜ğšğš ğšœğšğš™ğš™ğš˜ğš›ğšğšğš› ğš˜ğš ğš–ğšğšœğšœğš¢ ğš‹ğšğš—ğšœ & ğš•ğšğšğšğš’ğš—ğšğšœ\n",
       "1          163ãï¼æ„›ã‹ã£ã·ğŸ’œ26æ­³ğŸ’ å·¥ã€‡å¥½ããªå¥³ã®å­ğŸ’“ ãƒ•ã‚©ãƒ­ãƒ¼ã—ã¦ãã‚ŒãŸã‚‰DMã—ã¾ã™ğŸ§¡\n",
       "2                                                csu\n",
       "3  Writer @Washinformer @SpelmanCollege alumna #D...\n",
       "4    Iâ€™m unemployed and live with my parents. MOOPS!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#convert to dataframe, and name the original tweet as tweet\n",
    "\n",
    "print(\"robyn tweet\")\n",
    "\n",
    "robyn_tweet = pd.DataFrame(twitter_data['robynkonichiwa'])\n",
    "robyn_tweet.columns = ['tweet']\n",
    "display(robyn_tweet.head())\n",
    "\n",
    "print(\"cher tweet\")\n",
    "\n",
    "cher_tweet = pd.DataFrame(twitter_data['cher'])\n",
    "cher_tweet.columns = ['tweet']\n",
    "display(cher_tweet.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99e8ae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop(tokens):\n",
    "    return [t for t in tokens if t.lower() not in stopwords]\n",
    "\n",
    "def tokenize(text):\n",
    "    # Remove punctuation characters, split on whitespace, and fold to lowercase\n",
    "    tokens = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    return tokens\n",
    "\n",
    "def prepare_text(row):\n",
    "    original_text = row['tweet']\n",
    "    \n",
    "    # Apply the pipeline to the 'tweet' column\n",
    "    tokens = original_text\n",
    "    for transform in pipeline:\n",
    "        tokens = transform(tokens)\n",
    "    \n",
    "    return pd.Series({'tweet': original_text, 'tokens': tokens})\n",
    "\n",
    "pipeline = [tokenize, remove_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f655960c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robyn tweet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"I love chill\" â€¢Facebook / Instagram / SoundCl...</td>\n",
       "      <td>[love, chill, facebook, instagram, soundcloud,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>books, movies, music, nature &amp; TV shows. OG Sw...</td>\n",
       "      <td>[books, movies, music, nature, tv, shows, og, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Am)auteur en herbe ğŸŒ± - juriste en paille ğŸ¤¡ - ...</td>\n",
       "      <td>[auteur, en, herbe, juriste, en, paille, ami, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This Twitter profile is full of sarcasm and ra...</td>\n",
       "      <td>[twitter, profile, full, sarcasm, rants, occas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flora Youssef - Blogger &amp; Founder Posting revi...</td>\n",
       "      <td>[flora, youssef, blogger, founder, posting, re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  \"I love chill\" â€¢Facebook / Instagram / SoundCl...   \n",
       "1  books, movies, music, nature & TV shows. OG Sw...   \n",
       "2  (Am)auteur en herbe ğŸŒ± - juriste en paille ğŸ¤¡ - ...   \n",
       "3  This Twitter profile is full of sarcasm and ra...   \n",
       "4  Flora Youssef - Blogger & Founder Posting revi...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [love, chill, facebook, instagram, soundcloud,...  \n",
       "1  [books, movies, music, nature, tv, shows, og, ...  \n",
       "2  [auteur, en, herbe, juriste, en, paille, ami, ...  \n",
       "3  [twitter, profile, full, sarcasm, rants, occas...  \n",
       "4  [flora, youssef, blogger, founder, posting, re...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cher tweet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ğ™¿ğš›ğš˜ğšğš ğšœğšğš™ğš™ğš˜ğš›ğšğšğš› ğš˜ğš ğš–ğšğšœğšœğš¢ ğš‹ğšğš—ğšœ &amp; ğš•ğšğšğšğš’ğš—ğšğšœ</td>\n",
       "      <td>[ğ™¿ğš›ğš˜ğšğš, ğšœğšğš™ğš™ğš˜ğš›ğšğšğš›, ğš˜ğš, ğš–ğšğšœğšœğš¢, ğš‹ğšğš—ğšœ, ğš•ğšğšğšğš’ğš—ğšğšœ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>163ãï¼æ„›ã‹ã£ã·ğŸ’œ26æ­³ğŸ’ å·¥ã€‡å¥½ããªå¥³ã®å­ğŸ’“ ãƒ•ã‚©ãƒ­ãƒ¼ã—ã¦ãã‚ŒãŸã‚‰DMã—ã¾ã™ğŸ§¡</td>\n",
       "      <td>[163, æ„›ã‹ã£ã·, 26æ­³, å·¥ã€‡å¥½ããªå¥³ã®å­, ãƒ•ã‚©ãƒ­ãƒ¼ã—ã¦ãã‚ŒãŸã‚‰dmã—ã¾ã™]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>csu</td>\n",
       "      <td>[csu]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Writer @Washinformer @SpelmanCollege alumna #D...</td>\n",
       "      <td>[writer, washinformer, spelmancollege, alumna,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iâ€™m unemployed and live with my parents. MOOPS!</td>\n",
       "      <td>[unemployed, live, parents, moops]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0           ğ™¿ğš›ğš˜ğšğš ğšœğšğš™ğš™ğš˜ğš›ğšğšğš› ğš˜ğš ğš–ğšğšœğšœğš¢ ğš‹ğšğš—ğšœ & ğš•ğšğšğšğš’ğš—ğšğšœ   \n",
       "1          163ãï¼æ„›ã‹ã£ã·ğŸ’œ26æ­³ğŸ’ å·¥ã€‡å¥½ããªå¥³ã®å­ğŸ’“ ãƒ•ã‚©ãƒ­ãƒ¼ã—ã¦ãã‚ŒãŸã‚‰DMã—ã¾ã™ğŸ§¡   \n",
       "2                                                csu   \n",
       "3  Writer @Washinformer @SpelmanCollege alumna #D...   \n",
       "4    Iâ€™m unemployed and live with my parents. MOOPS!   \n",
       "\n",
       "                                              tokens  \n",
       "0      [ğ™¿ğš›ğš˜ğšğš, ğšœğšğš™ğš™ğš˜ğš›ğšğšğš›, ğš˜ğš, ğš–ğšğšœğšœğš¢, ğš‹ğšğš—ğšœ, ğš•ğšğšğšğš’ğš—ğšğšœ]  \n",
       "1        [163, æ„›ã‹ã£ã·, 26æ­³, å·¥ã€‡å¥½ããªå¥³ã®å­, ãƒ•ã‚©ãƒ­ãƒ¼ã—ã¦ãã‚ŒãŸã‚‰dmã—ã¾ã™]  \n",
       "2                                              [csu]  \n",
       "3  [writer, washinformer, spelmancollege, alumna,...  \n",
       "4                 [unemployed, live, parents, moops]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#add the tokens column to the original dataframe\n",
    "\n",
    "print(\"robyn tweet\")\n",
    "\n",
    "robyn_tweet[['tweet', 'tokens']] = robyn_tweet.apply(prepare_text, axis=1)\n",
    "display(robyn_tweet.head())\n",
    "\n",
    "print(\"cher tweet\")\n",
    "cher_tweet[['tweet', 'tokens']] = cher_tweet.apply(prepare_text, axis=1)\n",
    "display(cher_tweet.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2f7060d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robyn lyrics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Include Me Out\"\\n\\n\\n\\nIt is really very simp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Electric\"\\n\\n\\n\\nElectric...\\n\\nIt's electric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Beach 2K20\"\\n\\n\\n\\n(So you wanna go out?\\nHow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Love Kills\"\\n\\n\\n\\nIf you're looking for love...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Time Machine\"\\n\\n\\n\\nHey, what did I do?\\nCan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lyrics\n",
       "0  \"Include Me Out\"\\n\\n\\n\\nIt is really very simp...\n",
       "1  \"Electric\"\\n\\n\\n\\nElectric...\\n\\nIt's electric...\n",
       "2  \"Beach 2K20\"\\n\\n\\n\\n(So you wanna go out?\\nHow...\n",
       "3  \"Love Kills\"\\n\\n\\n\\nIf you're looking for love...\n",
       "4  \"Time Machine\"\\n\\n\\n\\nHey, what did I do?\\nCan..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cher lyrics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Come And Stay With Me\"\\n\\n\\n\\nI'll send away ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Pirate\"\\n\\n\\n\\nHe'll sail on with the summer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Stars\"\\n\\n\\n\\nI was never one for saying what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"These Days\"\\n\\n\\n\\nWell I've been out walking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Love So High\"\\n\\n\\n\\nEvery morning I would wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lyrics\n",
       "0  \"Come And Stay With Me\"\\n\\n\\n\\nI'll send away ...\n",
       "1  \"Pirate\"\\n\\n\\n\\nHe'll sail on with the summer ...\n",
       "2  \"Stars\"\\n\\n\\n\\nI was never one for saying what...\n",
       "3  \"These Days\"\\n\\n\\n\\nWell I've been out walking...\n",
       "4  \"Love So High\"\\n\\n\\n\\nEvery morning I would wa..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create your clean lyrics data here\n",
    "\n",
    "print(\"robyn lyrics\")\n",
    "\n",
    "robyn_lyrics = pd.DataFrame(lyrics_data['robyn'])\n",
    "robyn_lyrics.columns = ['lyrics']\n",
    "display(robyn_lyrics.head())\n",
    "\n",
    "print(\"cher lyrics\")\n",
    "\n",
    "cher_lyrics = pd.DataFrame(lyrics_data['cher'])\n",
    "cher_lyrics.columns = ['lyrics']\n",
    "display(cher_lyrics.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47a24157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robyn lyrics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Include Me Out\"\\n\\n\\n\\nIt is really very simp...</td>\n",
       "      <td>[include, really, simple, single, pulse, repea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Electric\"\\n\\n\\n\\nElectric...\\n\\nIt's electric...</td>\n",
       "      <td>[electric, electric, electric, natural, high, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Beach 2K20\"\\n\\n\\n\\n(So you wanna go out?\\nHow...</td>\n",
       "      <td>[beach, 2k20, wanna, go, gonna, get, ok, call,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Love Kills\"\\n\\n\\n\\nIf you're looking for love...</td>\n",
       "      <td>[love, kills, looking, love, get, heart, made,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Time Machine\"\\n\\n\\n\\nHey, what did I do?\\nCan...</td>\n",
       "      <td>[time, machine, hey, believe, fit, threw, stup...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lyrics  \\\n",
       "0  \"Include Me Out\"\\n\\n\\n\\nIt is really very simp...   \n",
       "1  \"Electric\"\\n\\n\\n\\nElectric...\\n\\nIt's electric...   \n",
       "2  \"Beach 2K20\"\\n\\n\\n\\n(So you wanna go out?\\nHow...   \n",
       "3  \"Love Kills\"\\n\\n\\n\\nIf you're looking for love...   \n",
       "4  \"Time Machine\"\\n\\n\\n\\nHey, what did I do?\\nCan...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [include, really, simple, single, pulse, repea...  \n",
       "1  [electric, electric, electric, natural, high, ...  \n",
       "2  [beach, 2k20, wanna, go, gonna, get, ok, call,...  \n",
       "3  [love, kills, looking, love, get, heart, made,...  \n",
       "4  [time, machine, hey, believe, fit, threw, stup...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cher lyrics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Come And Stay With Me\"\\n\\n\\n\\nI'll send away ...</td>\n",
       "      <td>[come, stay, send, away, false, pride, forsake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Pirate\"\\n\\n\\n\\nHe'll sail on with the summer ...</td>\n",
       "      <td>[pirate, sail, summer, wind, blows, day, every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Stars\"\\n\\n\\n\\nI was never one for saying what...</td>\n",
       "      <td>[stars, never, one, saying, really, feel, exce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"These Days\"\\n\\n\\n\\nWell I've been out walking...</td>\n",
       "      <td>[days, well, walking, much, talking, days, day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Love So High\"\\n\\n\\n\\nEvery morning I would wa...</td>\n",
       "      <td>[love, high, every, morning, would, wake, tie,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lyrics  \\\n",
       "0  \"Come And Stay With Me\"\\n\\n\\n\\nI'll send away ...   \n",
       "1  \"Pirate\"\\n\\n\\n\\nHe'll sail on with the summer ...   \n",
       "2  \"Stars\"\\n\\n\\n\\nI was never one for saying what...   \n",
       "3  \"These Days\"\\n\\n\\n\\nWell I've been out walking...   \n",
       "4  \"Love So High\"\\n\\n\\n\\nEvery morning I would wa...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [come, stay, send, away, false, pride, forsake...  \n",
       "1  [pirate, sail, summer, wind, blows, day, every...  \n",
       "2  [stars, never, one, saying, really, feel, exce...  \n",
       "3  [days, well, walking, much, talking, days, day...  \n",
       "4  [love, high, every, morning, would, wake, tie,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prepare_text2(row):\n",
    "    original_text = row['lyrics']\n",
    "    \n",
    "    # Apply the pipeline to the 'tweet' column\n",
    "    tokens = original_text\n",
    "    for transform in pipeline:\n",
    "        tokens = transform(tokens)\n",
    "    \n",
    "    return pd.Series({'lyrics': original_text, 'tokens': tokens})\n",
    "\n",
    "#add the tokens column to the original dataframe\n",
    "\n",
    "print(\"robyn lyrics\")\n",
    "\n",
    "robyn_lyrics[['lyrics', 'tokens']] = robyn_lyrics.apply(prepare_text2, axis=1)\n",
    "display(robyn_lyrics.head())\n",
    "\n",
    "print(\"cher lyrics\")\n",
    "cher_lyrics[['lyrics', 'tokens']] = cher_lyrics.apply(prepare_text2, axis=1)\n",
    "display(cher_lyrics.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dd0179",
   "metadata": {},
   "source": [
    "## Basic Descriptive Statistics\n",
    "\n",
    "Call your `descriptive_stats` function on both your lyrics data and your twitter data and for both artists (four total calls). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0bbedd9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robyn tweets Stats\n",
      "\n",
      "There are 1526444 tokens in the data.\n",
      "There are 205132 unique tokens in the data.\n",
      "There are 8847337 characters in the data.\n",
      "The lexical diversity is 0.134 in the data.\n",
      "The five most common words are:\n",
      "[('music', 16230), ('co', 13578), ('love', 12218), ('ï¸', 9964), ('https', 8071)]\n",
      "\n",
      "cher tweets Stats\n",
      "\n",
      "There are 15788215 tokens in the data.\n",
      "There are 960410 unique tokens in the data.\n",
      "There are 89397530 characters in the data.\n",
      "The lexical diversity is 0.061 in the data.\n",
      "The five most common words are:\n",
      "[('love', 225018), ('ï¸', 134391), ('life', 133418), ('music', 97060), ('co', 75488)]\n",
      "\n",
      " robyn lyrics Stats\n",
      "There are 13934 tokens in the data.\n",
      "There are 2107 unique tokens in the data.\n",
      "There are 68023 characters in the data.\n",
      "The lexical diversity is 0.151 in the data.\n",
      "The five most common words are:\n",
      "[('know', 308), ('love', 276), ('got', 252), ('like', 232), ('baby', 222)]\n",
      "\n",
      "cher lyrics Stats\n",
      "There are 32980 tokens in the data.\n",
      "There are 3555 unique tokens in the data.\n",
      "There are 159843 characters in the data.\n",
      "The lexical diversity is 0.108 in the data.\n",
      "The five most common words are:\n",
      "[('love', 1023), ('know', 488), ('oh', 325), ('time', 321), ('baby', 319)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[32980, 3555, 0.10779260157671317, 159843]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calls to descriptive_stats here\n",
    "\n",
    "print(\"robyn tweets Stats\\n\")\n",
    "\n",
    "descriptive_stats(\n",
    "    [token for tokens in robyn_tweet['tokens'] for token in tokens])\n",
    "\n",
    "print(\"\\ncher tweets Stats\\n\")\n",
    "\n",
    "descriptive_stats(\n",
    "    [token for tokens in cher_tweet['tokens'] for token in tokens])\n",
    "\n",
    "print(\"\\n robyn lyrics Stats\")\n",
    "\n",
    "descriptive_stats(\n",
    "    [token for tokens in robyn_lyrics['tokens'] for token in tokens])\n",
    "\n",
    "print(\"\\ncher lyrics Stats\")\n",
    "\n",
    "descriptive_stats(\n",
    "    [token for tokens in cher_lyrics['tokens'] for token in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46294409",
   "metadata": {},
   "source": [
    "Q: How do you think the \"top 5 words\" would be different if we left stopwords in the data? \n",
    "\n",
    "A: \n",
    "Without removing stopwords, the top 5 words might include common and non-meaningful words such as \"I,\" \"Me,\" \"you,\" \"myself,\" and \"and.\" These words, known as stopwords, are frequently used in the English language but often don't contribute significant meaning to the analysis.\n",
    "\n",
    "---\n",
    "\n",
    "Q: What were your prior beliefs about the lexical diversity between the artists? Does the difference (or lack thereof) in lexical diversity between the artists conform to your prior beliefs? \n",
    "\n",
    "A: \n",
    "Higher lexical diversity score would indicate a greater variety of unique words, reflecting a more diverse vocabulary. Surprisingly, the analysis revealed that Robyn has a higher score than Cher, which might differ from common expectations. This demonstrates the value of text analysis, leveraging data to provide more accurate and insightful results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4e1ac1",
   "metadata": {},
   "source": [
    "\n",
    "## Specialty Statistics\n",
    "\n",
    "The descriptive statistics we have calculated are quite generic. You will now calculate a handful of statistics tailored to these data.\n",
    "\n",
    "1. Ten most common emojis by artist in the twitter descriptions.\n",
    "1. Ten most common hashtags by artist in the twitter descriptions.\n",
    "1. Five most common words in song titles by artist. \n",
    "1. For each artist, a histogram of song lengths (in terms of number of tokens) \n",
    "\n",
    "We can use the `emoji` library to help us identify emojis and you have been given a function to help you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "753a5a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(emoji.is_emoji(\"â¤ï¸\"))\n",
    "assert(not emoji.is_emoji(\":-)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986fc4c0",
   "metadata": {},
   "source": [
    "### Emojis ğŸ˜\n",
    "\n",
    "What are the ten most common emojis by artist in the twitter descriptions? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "594faf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Artist: cher\n",
      "\n",
      "\n",
      "Ten most common emojis:\n",
      "\n",
      "â¤: 79223\n",
      "ğŸŒˆ: 47549\n",
      "â™¥: 33978\n",
      "ğŸ³: 33412\n",
      "âœ¨: 29468\n",
      "ğŸ’™: 21379\n",
      "ğŸ»: 20930\n",
      "ğŸŒŠ: 20223\n",
      "âœŒ: 16773\n",
      "ğŸ’œ: 16550\n",
      "\n",
      "Artist: robynkonichiwa\n",
      "\n",
      "\n",
      "Ten most common emojis:\n",
      "\n",
      "â¤: 4783\n",
      "ğŸŒˆ: 4685\n",
      "ğŸ³: 3528\n",
      "â™¥: 3103\n",
      "âœ¨: 2223\n",
      "ğŸ»: 1495\n",
      "âœŒ: 1189\n",
      "ğŸ¼: 1139\n",
      "â™€: 836\n",
      "ğŸ’™: 809\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "import emoji\n",
    "from collections import Counter\n",
    "\n",
    "def extract_emojis(text):\n",
    "    return [c for c in text if emoji.is_emoji(c)]\n",
    "\n",
    "emoji_counts = {}\n",
    "\n",
    "for artist, tweets in twitter_data.items():\n",
    "    emoji_counts[artist] = Counter()\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        emojis = extract_emojis(tweet)\n",
    "        emoji_counts[artist].update(emojis)\n",
    "\n",
    "# ten most common emojis for each artist\n",
    "for artist, emojis in emoji_counts.items():\n",
    "    print(f\"\\nArtist: {artist}\\n\")\n",
    "    print(\"\\nTen most common emojis:\\n\")\n",
    "    \n",
    "    for emoji, count in emojis.most_common(10):\n",
    "        print(f\"{emoji}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab9b770",
   "metadata": {},
   "source": [
    "### Hashtags\n",
    "\n",
    "What are the ten most common hashtags by artist in the twitter descriptions? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd001295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Artist: cher\n",
      "\n",
      "\n",
      "Ten most common hashtags:\n",
      "\n",
      "#BLM: 9535\n",
      "#Resist: 6036\n",
      "#BlackLivesMatter: 4681\n",
      "#resist: 3797\n",
      "#FBR: 3239\n",
      "#TheResistance: 2995\n",
      "#blacklivesmatter: 2645\n",
      "#1: 2627\n",
      "#Resistance: 1919\n",
      "#RESIST: 1823\n",
      "\n",
      "Artist: robynkonichiwa\n",
      "\n",
      "\n",
      "Ten most common hashtags:\n",
      "\n",
      "#BlackLivesMatter: 337\n",
      "#BLM: 306\n",
      "#blacklivesmatter: 208\n",
      "#1: 199\n",
      "#music: 174\n",
      "#Music: 113\n",
      "#EDM: 86\n",
      "#LGBTQ: 75\n",
      "#TeamFollowBack: 59\n",
      "#blm: 56\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def extract_hashtags(text):\n",
    "    return re.findall(r\"#(\\w+)\", text)\n",
    "\n",
    "hashtag_counts = {}\n",
    "\n",
    "for artist, tweets in twitter_data.items():\n",
    "    hashtag_counts[artist] = Counter()\n",
    "\n",
    "    for tweet in tweets:\n",
    "        hashtags = extract_hashtags(tweet)\n",
    "        hashtag_counts[artist].update(hashtags)\n",
    "\n",
    "# Print the ten most common hashtags for each artist\n",
    "for artist, hashtags in hashtag_counts.items():\n",
    "    print(f\"\\nArtist: {artist}\\n\")\n",
    "    print(\"\\nTen most common hashtags:\\n\")\n",
    "\n",
    "    for hashtag, count in hashtags.most_common(10):\n",
    "        print(f\"#{hashtag}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10f21d5",
   "metadata": {},
   "source": [
    "### Song Titles\n",
    "\n",
    "What are the five most common words in song titles by artist? The song titles should be on the first line of the lyrics pages, so if you have kept the raw file contents around, you will not need to re-read the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df6fbba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Artist: robyn\n",
      "\n",
      "\n",
      "Ten most common song titles :\n",
      "\n",
      "Me: 11\n",
      "You: 8\n",
      "The: 8\n",
      "My: 8\n",
      "Love: 6\n",
      "\n",
      "Artist: cher\n",
      "\n",
      "\n",
      "Ten most common song titles :\n",
      "\n",
      "The: 53\n",
      "You: 40\n",
      "Love: 38\n",
      "I: 32\n",
      "To: 28\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "from collections import Counter\n",
    "import re  \n",
    "\n",
    "def extract_title(text):\n",
    "    return re.findall(r'\"(.*)\"', text)[0].split()\n",
    "\n",
    "title_counts = {}\n",
    "\n",
    "for artist, lyrics in lyrics_data.items():\n",
    "    title_counts[artist] = Counter()\n",
    "    \n",
    "    for lyric in lyrics:\n",
    "        title = extract_title(lyric)\n",
    "        title_counts[artist].update(title)\n",
    "\n",
    "# ten most common song titles for each artist\n",
    "for artist, titles in title_counts.items():\n",
    "    print(f\"\\nArtist: {artist}\\n\")\n",
    "    print(\"\\nTen most common song titles :\\n\")\n",
    "    \n",
    "    for title, count in titles.most_common(5):\n",
    "        print(f\"{title}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd4fd71",
   "metadata": {},
   "source": [
    "### Song Lengths\n",
    "\n",
    "For each artist, a histogram of song lengths (in terms of number of tokens). If you put the song lengths in a data frame with an artist column, matplotlib will make the plotting quite easy. An example is given to help you out. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "805a1e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist\n",
       "Artist 1    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Artist 2    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Name: length, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD4CAYAAAD7CAEUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAbQElEQVR4nO3dfZAV9Z3v8fdHxGCy5CI4RsLgAhZGKHRHMgEs3ezFLDdA3ZWolQ1qiRo2yApX83BzM5otY27VKmoMiXUJLCq1oBE0bjSzZlIuMRpLKygjIWQQlZEdZIAosusDaxQh3/vH6dHD4cxMN0zPw5nPq6rrdP8e+vy+Psy3fn26f62IwMzMLK1jenoAZmbWtzhxmJlZJk4cZmaWiROHmZll4sRhZmaZHNvTA+gOJ554YowaNaqnh2Fm1qc899xzr0dEVWl5v0gco0aNorGxsaeHYWbWp0jaXq7cl6rMzCwTJw4zM8vEicPMzDLpF79xmFn/9v7779Pa2sq7777b00PplQYNGkR1dTUDBw5M1d6Jw8wqXmtrK4MHD2bUqFFI6unh9CoRwd69e2ltbWX06NGp+vhSlZlVvHfffZdhw4Y5aZQhiWHDhmWajTlxmFm/4KTRvqz/bJw4zMwsE//GYWb9zuK1L3Xp+b427bRU7R566CEuvPBCtmzZwumnn162zRtvvMF9993H1VdfDcCuXbu45pprePDBB1O1L/XlL3+ZRx55hJNOOommpqZU4+yME4f1mK7+n7dN2v+Jzbrb6tWrOffcc1mzZg033njjYfUHDx7kjTfe4Ec/+tEHieCTn/xku0kDOKx9qSuuuIKFCxcyZ86cLokBfKnKzKxb7Nu3j6effpq7776bNWvWfFD+xBNPMHXqVC655BLOOOMM6urqePnll6mpqeGb3/wmLS0tTJgwAYDNmzczadIkampqOPPMM9m6deth7Ut99rOfZejQoV0ai2ccZmbd4OGHH2b69OmcdtppDB06lA0bNjBx4kQAnn32WZqamhg9ejQtLS00NTWxceNGAFpaWj44x7Jly7j22mu59NJL2b9/PwcPHmTRokWHtO8OnnGYmXWD1atXM3v2bABmz57N6tWrP6ibNGlSqmcozj77bG666SZuueUWtm/fzvHHH5/beDviGYeZWc727t3Lr371K5qampDEwYMHkcStt94KwMc+9rFU57nkkkuYPHkyP//5z/n85z/PXXfdxZgxY/IcelmecZiZ5ezBBx9kzpw5bN++nZaWFnbs2MHo0aN56qmnDms7ePBg3n777bLn2bZtG2PGjOGaa67h/PPPZ9OmTR22z4tnHGbW73T3nXerV6+mrq7ukLKLLrqI++67jy996UuHlA8bNoxzzjmHCRMmMGPGDBYsWPBB3f3338+9997LwIEDOfnkk7nhhhsYOnToIe1vu+22Q8538cUX88QTT/D6669TXV3Nd7/7XebOnXtU8SgijuoEHZ5cmg78EBgA3BURi0rqldTPBN4BroiIDZIGAU8CH6GQ3B6MiO8kfW4EvgLsSU5zfUQ0dDSO2tra8Iuceh/fjmvdZcuWLYwbN66nh9GrlftnJOm5iKgtbZvbjEPSAGAJMA1oBdZLqo+I54uazQDGJttkYGny+R5wXkTskzQQeErSLyJiXdJvcUR8L6+xm5lZ+/L8jWMS0BwR2yJiP7AGmFXSZhawKgrWAUMkDU+O9yVtBiZbflMjMzNLLc/EMQLYUXTcmpSlaiNpgKSNwGvA2oh4pqjdQkmbJK2QdEK5L5c0T1KjpMY9e/aUa2JmZkcgz8RRbrnF0llDu20i4mBE1ADVwCRJE5L6pcCpQA2wG7i93JdHxPKIqI2I2qqqquyjNzOzsvJMHK3AyKLjamBX1jYR8QbwBDA9OX41SSp/Au6kcEnMzMy6SZ6JYz0wVtJoSccBs4H6kjb1wBwVTAHejIjdkqokDQGQdDzw18ALyfHwov4XAF2z3KOZmaWS211VEXFA0kLgUQq3466IiM2S5if1y4AGCrfiNlO4HffKpPtwYGVyZ9YxwAMR8UhSd6ukGgqXtFqAq/KKwcwq1OM3d+35pl6Xqll3L6u+Y8cO5syZwx/+8AeOOeYY5s2bx7XXXpsyqPbl+uR4RDRExGkRcWpE/GNStixJGiR3Ty1I6s+IiMakfFNEnBURZ0bEhIj4v0XnvCxpe2ZEnB8Ru/OMwcysqxQvq15O8bLqbdIuq17Osccey+23386WLVtYt24dS5Ys4fnnny/bNgsvOWJm1g16Yln14cOHf7AC7+DBgxk3bhw7d+486li85IiZWTfo6WXVW1pa+O1vf8vkyZOPOhbPOMzMukFPLqu+b98+LrroIn7wgx/w8Y9//MgCKOIZh5lZznpyWfX333+fiy66iEsvvZQLL7zwqGMBzzjMzHLXU8uqRwRz585l3LhxfP3rX++yeDzjMLP+J+Xts12lp5ZVf/rpp7nnnns444wzqKmpAeCmm25i5syZRxVPrsuq9xZeVr138rLq1l28rHrnsiyr7ktVZmaWiROHmZll4sRhZv1Cf7gsf6Sy/rNx4jCzijdo0CD27t3r5FFGRLB3714GDRqUuo/vqjKzilddXU1rayt+qVt5gwYNorq6OnV7Jw4zq3gDBw5M9WS2peNLVWZmlolnHGb9VVe/k6JUNz9kZ93HMw4zM8vEicPMzDJx4jAzs0ycOMzMLJNcE4ek6ZJelNQsqa5MvSTdkdRvkjQxKR8k6VlJv5O0WdJ3i/oMlbRW0tbk84Q8YzAzs0PlljgkDQCWADOA8cDFksaXNJsBjE22ecDSpPw94LyI+AugBpguaUpSVwc8FhFjgceSYzMz6yZ5zjgmAc0RsS0i9gNrgFklbWYBq6JgHTBE0vDkeF/SZmCyRVGflcn+SuALOcZgZmYl8kwcI4AdRcetSVmqNpIGSNoIvAasjYhnkjafiIjdAMnnSeW+XNI8SY2SGr3MgJlZ18kzcahMWekKY+22iYiDEVEDVAOTJE3I8uURsTwiaiOitqqqKktXMzPrQJ6JoxUYWXRcDezK2iYi3gCeAKYnRa9KGg6QfL7WZSM2M7NO5Zk41gNjJY2WdBwwG6gvaVMPzEnurpoCvBkRuyVVSRoCIOl44K+BF4r6XJ7sXw78LMcYzMysRG5rVUXEAUkLgUeBAcCKiNgsaX5SvwxoAGYCzcA7wJVJ9+HAyuTOrGOAByLikaRuEfCApLnAK8AX84rBzMwOl+sihxHRQCE5FJctK9oPYEGZfpuAs9o5517gc107Uqski9e+lMt5vzbttFzOa9bX+MlxMzPLxInDzMwyceIwM7NMnDjMzCwTJw4zM8vEicPMzDJx4jAzs0ycOMzMLBMnDjMzy8SJw8zMMnHiMDOzTHJdq8rMjsLjN/f0CMzK8ozDzMwyceIwM7NMnDjMzCwTJw4zM8vEicPMzDJx4jAzs0ycOMzMLJNcE4ek6ZJelNQsqa5MvSTdkdRvkjQxKR8p6XFJWyRtlnRtUZ8bJe2UtDHZZuYZg5mZHSq3BwAlDQCWANOAVmC9pPqIeL6o2QxgbLJNBpYmnweAb0TEBkmDgeckrS3quzgivpfX2M3MrH15zjgmAc0RsS0i9gNrgFklbWYBq6JgHTBE0vCI2B0RGwAi4m1gCzAix7GamVlKeSaOEcCOouNWDv/j32kbSaOAs4BniooXJpe2Vkg6octGbGZmncozcahMWWRpI+nPgH8BvhoRbyXFS4FTgRpgN3B72S+X5klqlNS4Z8+ejEM3M7P25Jk4WoGRRcfVwK60bSQNpJA0fhwRP21rEBGvRsTBiPgTcCeFS2KHiYjlEVEbEbVVVVVHHYyZmRXkmTjWA2MljZZ0HDAbqC9pUw/MSe6umgK8GRG7JQm4G9gSEd8v7iBpeNHhBUBTfiGYmVmp3O6qiogDkhYCjwIDgBURsVnS/KR+GdAAzASagXeAK5Pu5wCXAb+XtDEpuz4iGoBbJdVQuKTVAlyVVwxmZna4XN/HkfyhbygpW1a0H8CCMv2eovzvH0TEZV08TEth8dqXenoIvY/fl2H9lJ8cNzOzTJw4zMwsEycOMzPLJFXikDQh74GYmVnfkHbGsUzSs5KuljQkzwGZmVnvlipxRMS5wKUUHtZrlHSfpGm5jszMzHql1L9xRMRW4B+AbwF/Bdwh6QVJF+Y1ODMz633S/sZxpqTFFFapPQ/4m4gYl+wvznF8ZmbWy6R9APD/UVgX6vqI+GNbYUTskvQPuYzMzMx6pbSJYybwx4g4CCDpGGBQRLwTEffkNjozM+t10v7G8Uvg+KLjjyZlZmbWz6RNHIMiYl/bQbL/0XyGZGZmvVnaxPFfkia2HUj6NPDHDtqbmVmFSvsbx1eBn0hqexHTcOBLuYzIzMx6tVSJIyLWSzod+BSF5c5fiIj3cx2ZmZn1Slnex/EZYFTS5yxJRMSqXEZlZma9VqrEIeke4FRgI3AwKQ7AicPMrJ9JO+OoBcYnb+wzM7N+LO1dVU3AyXkOxMzM+oa0ieNE4HlJj0qqb9s66yRpuqQXJTVLqitTL0l3JPWb2m75lTRS0uOStkjaLOnaoj5DJa2VtDX5PCFtsGZmdvTSXqq6MeuJJQ0AlgDTgFZgvaT6iHi+qNkMYGyyTQaWJp8HgG9ExAZJg4HnJK1N+tYBj0XEoiQZ1VFYsdfMzLpB2vdx/BpoAQYm++uBDZ10mwQ0R8S2iNgPrAFmlbSZBayKgnXAEEnDI2J3RGxIvvttCqvyjijqszLZXwl8IU0MZmbWNdIuq/4V4EHgn5KiEcDDnXQbAewoOm7lwz/+qdtIGgWcBTyTFH0iInYDJJ8npYnBzMy6RtrfOBYA5wBvwQcvdersD7bKlJXeldVhG0l/BvwL8NWIeCvlWNv6zpPUKKlxz549WbqamVkH0iaO95LLTQBIOpbDk0CpVgqvmm1TDexK20bSQApJ48cR8dOiNq9KGp60GQ68Vu7LI2J5RNRGRG1VVVUnQzUzs7TS/jj+a0nXA8cn7xq/GvjXTvqsB8ZKGg3sBGYDl5S0qQcWSlpD4UfxNyNityQBdwNbIuL7ZfpcDixKPn+WMgYz606P35z/d0y9Lv/vsMOknXHUAXuA3wNXAQ0U3j/erog4ACwEHqXw4/YDEbFZ0nxJ85NmDcA2oJnCGwavTsrPAS4DzpO0MdlmJnWLgGmStlK4Y2tRyhjMzKwLpF3k8E8U/rDfmeXkEdFAITkUly0r2g8Kv5+U9nuK8r9/EBF7gc9lGYeZmXWdtGtV/TtlftOIiDFdPiIzM+vVsqxV1WYQ8EVgaNcPx8zMeru0DwDuLdp2RsQPgPPyHZqZmfVGaS9VTSw6PIbCDGRwLiMy66UWr33pkOMpr+ztkvOePWZYl5zHrLukvVR1e9H+AQrLj/xtl4/GzMx6vbR3VU3NeyBmZtY3pL1U9fWO6ss8pGdmZhUqy11Vn6Hw1DbA3wBPcugChWZm1g+kTRwnAhOTJc6RdCPwk4j4u7wGZmZmvVPaJUdOAfYXHe8HRnX5aMzMrNdLO+O4B3hW0kMUniC/AFiV26jMzKzXSntX1T9K+gXwl0nRlRHx2/yGZWZmvVXaS1UAHwXeiogfAq3JculmZtbPpH117HeAbwFti98PBO7Na1BmZtZ7pZ1xXACcD/wXQETswkuOmJn1S2kTx/7k3RkBIOlj+Q3JzMx6s7SJ4wFJ/wQMkfQV4JdkfKmTmZlVhk7vqkre/30/cDrwFvAp4IaIWJvz2MzMrBfqNHFEREh6OCI+DThZmJn1c2kvVa2T9JmsJ5c0XdKLkpol1ZWpl6Q7kvpNxe/9kLRC0muSmkr63Chpp6SNyTYz67jMzOzIpU0cUykkj5eTP/C/l7Spow6SBgBLgBnAeOBiSeNLms0AxibbPGBpUd0/A9PbOf3iiKhJtoaUMZiZWRfo8FKVpFMi4hUKf+CzmgQ0R8S25FxrgFnA80VtZgGrkju21kkaIml4ROyOiCcljTqC7zUzsxx1NuN4GCAitgPfj4jtxVsnfUdw6LLrrUlZ1jblLExmPisknZCivZmZdZHOEoeK9sdkPLfKlMURtCm1FDgVqAF2c+hrbT88sTRPUqOkxj179nRySjMzS6uzu6qinf00WoGRRcfVwK4jaHPogCJebduXdCfwSDvtlgPLAWpra7OOvc9avPalnh6CmVW4zmYcfyHpLUlvA2cm+29JelvSW530XQ+MlTRa0nHAbD58g2CbemBOcnfVFODNiNjd0UklDS86vABoaq+tmZl1vQ5nHBEx4EhPHBEHJC0EHgUGACsiYrOk+Un9MqABmAk0A+8AV7b1l7Qa+O/AiZJage9ExN3ArZJqKMyAWoCrjnSMZmaWXdoXOR2R5FbZhpKyZUX7ASxop+/F7ZRf1pVjNDOzbLK8j8PMzMyJw8zMsnHiMDOzTJw4zMwsEycOMzPLxInDzMwyceIwM7NMnDjMzCwTJw4zM8vEicPMzDJx4jAzs0ycOMzMLBMnDjMzy8SJw8zMMnHiMDOzTJw4zMwsEycOMzPLxInDzMwyceIwM7NMnDjMzCyTXBOHpOmSXpTULKmuTL0k3ZHUb5I0sahuhaTXJDWV9Bkqaa2krcnnCXnGYGZmh8otcUgaACwBZgDjgYsljS9pNgMYm2zzgKVFdf8MTC9z6jrgsYgYCzyWHJuZWTfJc8YxCWiOiG0RsR9YA8wqaTMLWBUF64AhkoYDRMSTwH+UOe8sYGWyvxL4Qh6DNzOz8vJMHCOAHUXHrUlZ1jalPhERuwGSz5PKNZI0T1KjpMY9e/ZkGriZmbUvz8ShMmVxBG2OSEQsj4jaiKitqqrqilOamRn5Jo5WYGTRcTWw6wjalHq17XJW8vnaUY7TzMwyODbHc68HxkoaDewEZgOXlLSpBxZKWgNMBt5suwzVgXrgcmBR8vmzLh21VYQpryzv6SFYd3j85nzPP/W6fM/fR+U244iIA8BC4FFgC/BARGyWNF/S/KRZA7ANaAbuBK5u6y9pNfAb4FOSWiXNTaoWAdMkbQWmJcdmZtZN8pxxEBENFJJDcdmyov0AFrTT9+J2yvcCn+vCYZqZWQZ+ctzMzDJx4jAzs0xyvVRlZp37zba9uZz37DHDcjmvmWccZmaWiROHmZll4sRhZmaZOHGYmVkmThxmZpaJE4eZmWXixGFmZpk4cZiZWSZOHGZmlokTh5mZZeLEYWZmmThxmJlZJk4cZmaWiROHmZll4sRhZmaZOHGYmVkmuSYOSdMlvSipWVJdmXpJuiOp3yRpYmd9Jd0oaaekjck2M88YzMzsULklDkkDgCXADGA8cLGk8SXNZgBjk20esDRl38URUZNsDXnFYGZmh8tzxjEJaI6IbRGxH1gDzCppMwtYFQXrgCGShqfsa2ZmPSDPd46PAHYUHbcCk1O0GZGi70JJc4BG4BsR8Z+lXy5pHoVZDKeccsoRhpCfxWtf6ukhmJkdkTxnHCpTFinbdNR3KXAqUAPsBm4v9+URsTwiaiOitqqqKtWAzcysc3nOOFqBkUXH1cCulG2Oa69vRLzaVijpTuCRrhuymZl1Js8Zx3pgrKTRko4DZgP1JW3qgTnJ3VVTgDcjYndHfZPfQNpcADTlGIOZmZXIbcYREQckLQQeBQYAKyJis6T5Sf0yoAGYCTQD7wBXdtQ3OfWtkmooXLpqAa7KKwYzMztcnpeqSG6VbSgpW1a0H8CCtH2T8su6eJhmZpaBnxw3M7NMnDjMzCwTJw4zM8vEicPMzDJx4jAzs0ycOMzMLBMnDjMzy8SJw8zMMnHiMDOzTHJ9ctzMes5vtu3N5bxnjxmWy3mt73DisB4x5ZXlPT0Es849fnO+5596Xb7nz4kvVZmZWSZOHGZmlokTh5mZZeLEYWZmmfjH8U4sXvtSTw/BzKxX8YzDzMwyceIwM7NMfKnKzKyn5P2cCOTyrEiuiUPSdOCHwADgrohYVFKvpH4m8A5wRURs6KivpKHA/cAooAX424j4zzzjMLMP5fFEup9G71tySxySBgBLgGlAK7BeUn1EPF/UbAYwNtkmA0uByZ30rQMei4hFkuqS42/lFUd/5Se7zaw9ef7GMQlojohtEbEfWAPMKmkzC1gVBeuAIZKGd9J3FrAy2V8JfCHHGMzMrESel6pGADuKjlspzCo6azOik76fiIjdABGxW9JJ5b5c0jxgXnK4T9KLRxJEDzgReL2nB9HN+mPM0D/j7o8xQ4/Gff3RdP7zcoV5Jg6VKYuUbdL07VBELAf63PUWSY0RUdvT4+hO/TFm6J9x98eYofLizvNSVSswsui4GtiVsk1HfV9NLmeRfL7WhWM2M7NO5Jk41gNjJY2WdBwwG6gvaVMPzFHBFODN5DJUR33rgcuT/cuBn+UYg5mZlcjtUlVEHJC0EHiUwi21KyJis6T5Sf0yoIHCrbjNFG7HvbKjvsmpFwEPSJoLvAJ8Ma8Yekifu7zWBfpjzNA/4+6PMUOFxa2ITD8dmJlZP+clR8zMLBMnDjMzy8SJoxtJWiHpNUlNRWVDJa2VtDX5PKGo7jpJzZJelPT5nhn10Wsn7tskvSBpk6SHJA0pquvzcZeLuajuf0sKSScWlfX5mKH9uCX9ryS2zZJuLSrv83G38993jaR1kjZKapQ0qaiuz8dMRHjrpg34LDARaCoquxWoS/brgFuS/fHA74CPAKOBl4EBPR1DF8b9P4Bjk/1bKi3ucjEn5SMp3PSxHTixkmLu4N/1VOCXwEeS45MqKe52Yv43YEayPxN4opJi9oyjG0XEk8B/lBS3t4TKLGBNRLwXEf9O4c6zSfRB5eKOiH+LiAPJ4ToKz+pAhcTdzr9rgMXA/+HQB1orImZoN+6/BxZFxHtJm7Znryoi7nZiDuDjyf5/48Pn0CoiZieOnnfIEipA2xIq7S3HUom+DPwi2a/YuCWdD+yMiN+VVFVszInTgL+U9IykX0v6TFJeyXF/FbhN0g7ge0Db2uYVEbMTR+911Muu9AWSvg0cAH7cVlSmWZ+PW9JHgW8DN5SrLlPW52MucixwAjAF+CaF57BEZcf998DXImIk8DXg7qS8ImJ24uh57S2hkmbJlj5N0uXA/wQujeQCMJUb96kUrmn/TlILhbg2SDqZyo25TSvw0yh4FvgThUX/Kjnuy4GfJvs/4cPLURURsxNHz2tvCZV6YLakj0gaTeGdJc/2wPhykbyo61vA+RHxTlFVRcYdEb+PiJMiYlREjKLwB2RiRPyBCo25yMPAeQCSTgOOo7BSbCXHvQv4q2T/PGBrsl8ZMff0r/P9aQNWA7uB9yn84ZgLDAMeo/Af1mPA0KL236Zw18WLJHdo9MWtnbibKVzr3Zhsyyop7nIxl9S3kNxVVSkxd/Dv+jjgXqAJ2ACcV0lxtxPzucBzFO6gegb4dCXF7CVHzMwsE1+qMjOzTJw4zMwsEycOMzPLxInDzMwyceIwM7NMnDjMzCwTJw4zM8vk/wNY2c4ZjfCQwAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_replicates = 1000\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"artist\" : ['Artist 1'] * num_replicates + ['Artist 2']*num_replicates,\n",
    "    \"length\" : np.concatenate((np.random.poisson(125,num_replicates),np.random.poisson(150,num_replicates)))\n",
    "})\n",
    "\n",
    "df.groupby('artist')['length'].plot(kind=\"hist\",density=True,alpha=0.5,legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fde9ebb",
   "metadata": {},
   "source": [
    "Since the lyrics may be stored with carriage returns or tabs, it may be useful to have a function that can collapse whitespace, using regular expressions, and be used for splitting. \n",
    "\n",
    "Q: What does the regular expression `'\\s+'` match on? \n",
    "\n",
    "A: \n",
    "It means matches one or more whitespace characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0e34516",
   "metadata": {},
   "outputs": [],
   "source": [
    "collapse_whitespace = re.compile(r'\\s+')\n",
    "\n",
    "def tokenize_lyrics(lyric) : \n",
    "    \"\"\"strip and split on whitespace\"\"\"\n",
    "    return([item.lower() for item in collapse_whitespace.split(lyric)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2294c440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your lyric length comparison chart here. \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dictionary to store the average lyric lengths for each artist\n",
    "average_lengths = {}\n",
    "\n",
    "# Calculate the average lyric length for each artist\n",
    "for artist, lyrics_list in lyrics_data.items():\n",
    "    total_length = 0\n",
    "    num_lyrics = len(lyrics_list)\n",
    "    for lyrics in lyrics_list:\n",
    "        total_length += len(lyrics)\n",
    "    average_length = total_length / num_lyrics\n",
    "    average_lengths[artist] = average_length\n",
    "\n",
    "# Convert the dictionary to lists for plotting\n",
    "artists = list(average_lengths.keys())\n",
    "lengths = list(average_lengths.values())\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.bar(artists, lengths)\n",
    "plt.xlabel('Artist')\n",
    "plt.ylabel('Average Lyric Length')\n",
    "plt.title('Lyric Length Comparison')\n",
    "plt.xticks(rotation=45)  # Specify the rotation angle for better readability\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e141523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
